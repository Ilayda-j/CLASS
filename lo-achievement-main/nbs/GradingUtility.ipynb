{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradingUtility.ipynb\n",
    "> A notebook for formulating prompts and prompting\n",
    "\n",
    "In this notebook, we create some base functionality for grading and uploading student responses in a simplified, unified way.\n",
    "\n",
    ":::{.callout-caution}\n",
    "These notebooks are development notebooks, meaning that they are meant to be run locally or somewhere that supports navigating a full repository (in other words, not Google Colab unless you clone the entire repository to drive and then mount the Drive-Repository.) However, it is expected if you're able to do all of those steps, you're likely also able to figure out the required pip installs for development there.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp GradingUtility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import io\n",
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# \"global\" variables modified by mutability\n",
    "grade_settings = {'learning_objectives':None,\n",
    "                  'json_file_path':None,\n",
    "                  'json_files':None }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class InstructorGradingConfig:\n",
    "    def __init__(self):\n",
    "        # layouts to help with styling\n",
    "        self.items_layout = widgets.Layout(width='auto')\n",
    "\n",
    "        self.box_layout = widgets.Layout(display='flex',\n",
    "                                          flex_flow='column',\n",
    "                                          align_items='stretch',\n",
    "                                          width='50%',\n",
    "                                          border='solid 1px gray',\n",
    "                                          padding='0px 30px 20px 30px')\n",
    "\n",
    "        # Create all components\n",
    "        self.ui_title = widgets.HTML(value=\"<h2>Instructor Grading Configuration</h2>\")\n",
    "\n",
    "        self.run_button = widgets.Button(description='Submit', button_style='success', icon='check')\n",
    "        self.status_output = widgets.Output()\n",
    "        self.status_output.append_stdout('Waiting...')\n",
    "\n",
    "        # Setup click behavior\n",
    "        self.run_button.on_click(self._setup_environment)\n",
    "\n",
    "        # Reset rest of state\n",
    "        self.reset_state()\n",
    "\n",
    "    def reset_state(self, close_all=False):\n",
    "\n",
    "        if close_all:\n",
    "            self.learning_objectives_text.close()\n",
    "            self.file_upload.close()\n",
    "            self.file_upload_box.close()\n",
    "            #self.ui_container.close()\n",
    "\n",
    "        self.learning_objectives_text = widgets.Textarea(value='', description='Learning Objectives',\n",
    "                                                         placeholder='Learning objectives: 1. Understand and implement classes in object-oriented programming',\n",
    "                                                         layout=self.items_layout,\n",
    "                                                         style={'description_width': 'initial'})\n",
    "        self.file_upload = widgets.FileUpload(\n",
    "            accept='.zip',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "            multiple=False  # True to accept multiple files upload else False\n",
    "        )\n",
    "        self.file_upload_box = widgets.HBox([widgets.Label('Upload User Files:\\t'), self.file_upload])\n",
    "\n",
    "\n",
    "        # Create a VBox container to arrange the widgets vertically\n",
    "        self.ui_container = widgets.VBox([self.ui_title, self.learning_objectives_text,\n",
    "                                           self.file_upload_box, self.run_button, self.status_output],\n",
    "                                          layout=self.box_layout)\n",
    "\n",
    "\n",
    "    def _setup_environment(self, btn):\n",
    "        grade_settings['learning_objectives'] = self.learning_objectives_text.value\n",
    "        grade_settings['json_file_path'] = self.file_upload.value\n",
    "\n",
    "        if self.file_upload.value:\n",
    "            try:\n",
    "                input_file = list(self.file_upload.value.values())[0]\n",
    "                extracted_zip_dir = list(grade_settings['json_file_path'].keys())[0][:-4]\n",
    "            except:\n",
    "                input_file = self.file_upload.value[0]\n",
    "                extracted_zip_dir = self.file_upload.value[0]['name'][:-4]\n",
    "\n",
    "            self.status_output.clear_output()\n",
    "            self.status_output.append_stdout('Loading zip file...\\n')\n",
    "\n",
    "            with zipfile.ZipFile(io.BytesIO(input_file['content']), \"r\") as z:\n",
    "                z.extractall()\n",
    "                extracted_files = z.namelist()\n",
    "\n",
    "            self.status_output.append_stdout('Extracted files and directories: {0}\\n'.format(', '.join(extracted_files)))\n",
    "\n",
    "            # load all json files\n",
    "            grade_settings['json_files'] = glob.glob(''.join([extracted_zip_dir, '/**/*.json']), recursive=True)\n",
    "\n",
    "            #status_output.clear_output()\n",
    "            self.status_output.append_stdout('Loading successful!\\nLearning Objectives: {0}\\nExtracted JSON files: {1}'.format(grade_settings['learning_objectives'],\n",
    "                                                                                                        ', '.join(grade_settings['json_files'])))\n",
    "\n",
    "        else:\n",
    "            self.status_output.clear_output()\n",
    "            self.status_output.append_stdout('Please upload a zip file.')\n",
    "\n",
    "        # Clear values so they're not saved\n",
    "        self.learning_objectives_text.value = ''\n",
    "        self.reset_state(close_all=True)\n",
    "        self.run_ui_container()\n",
    "\n",
    "        with self.status_output:\n",
    "            print('Extracted files and directories: {0}\\n'.format(', '.join(extracted_files)))\n",
    "            print('Loading successful!\\nLearning Objectives: {0}\\nExtracted JSON files: {1}'.format(grade_settings['learning_objectives'],\n",
    "                                                                                                        ', '.join(grade_settings['json_files'])))\n",
    "            print('Submitted and Reset all values.')\n",
    "\n",
    "\n",
    "    def run_ui_container(self):\n",
    "        display(self.ui_container, clear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a936b681384365ba397ee89a77aba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Instructor Grading Configuration</h2>'), Textarea(value='', description='Learniâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FEEE\n",
      "======================================================================\n",
      "ERROR: test_setup_environment_invalid_file (__main__.TestInstructorGradingConfig)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_69693/2558061482.py\", line 24, in test_setup_environment_invalid_file\n",
      "    self.grading_config.file_upload.value = {'invalid_file': {'content': b'invalid content'}}\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 732, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 706, in set\n",
      "    new_value = self._validate(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 738, in _validate\n",
      "    value = self.validate(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 2867, in validate\n",
      "    value = super().validate(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 2151, in validate\n",
      "    self.error(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 844, in error\n",
      "    raise TraitError(e)\n",
      "traitlets.traitlets.TraitError: The 'value' trait of a FileUpload instance expected a tuple, not the dict {'invalid_file': {'content': b'invalid content'}}.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_setup_environment_no_file (__main__.TestInstructorGradingConfig)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_69693/2558061482.py\", line 19, in test_setup_environment_no_file\n",
      "    self.grading_config._setup_environment(None)\n",
      "  File \"/tmp/ipykernel_69693/2778765785.py\", line 53, in _setup_environment\n",
      "    grade_settings['learning_objectives'] = self.learning_objectives_text.value\n",
      "NameError: name 'grade_settings' is not defined\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_setup_environment_valid_file (__main__.TestInstructorGradingConfig)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_69693/2558061482.py\", line 31, in test_setup_environment_valid_file\n",
      "    self.grading_config.file_upload.value = {'valid_file.zip': {'content': b'valid zip content'}}\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 732, in __set__\n",
      "    self.set(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 706, in set\n",
      "    new_value = self._validate(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 738, in _validate\n",
      "    value = self.validate(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 2867, in validate\n",
      "    value = super().validate(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 2151, in validate\n",
      "    self.error(obj, value)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/traitlets.py\", line 844, in error\n",
      "    raise TraitError(e)\n",
      "traitlets.traitlets.TraitError: The 'value' trait of a FileUpload instance expected a tuple, not the dict {'valid_file.zip': {'content': b'valid zip content'}}.\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_reset_state (__main__.TestInstructorGradingConfig)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_69693/2558061482.py\", line 14, in test_reset_state\n",
      "    self.assertEqual(self.grading_config.file_upload.value, {})\n",
      "AssertionError: () != {}\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_run_ui_container (__main__.TestInstructorGradingConfig)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_69693/2558061482.py\", line 40, in test_run_ui_container\n",
      "    mock_display.assert_called_once_with(self.grading_config.ui_container, clear=True)\n",
      "  File \"/usr/lib/python3.10/unittest/mock.py\", line 930, in assert_called_once_with\n",
      "    raise AssertionError(msg)\n",
      "AssertionError: Expected 'display' to be called once. Called 0 times.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.297s\n",
      "\n",
      "FAILED (failures=2, errors=3)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import io\n",
    "import zipfile\n",
    "import glob\n",
    "from unittest.mock import patch\n",
    "\n",
    "class TestInstructorGradingConfig(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.grading_config = InstructorGradingConfig()\n",
    "\n",
    "    def test_reset_state(self):\n",
    "        self.grading_config.reset_state()\n",
    "        self.assertEqual(self.grading_config.learning_objectives_text.value, '')\n",
    "        self.assertEqual(self.grading_config.file_upload.value, {})\n",
    "        self.assertIsInstance(self.grading_config.ui_container, widgets.VBox)\n",
    "\n",
    "    def test_setup_environment_no_file(self):\n",
    "        with patch('sys.stdout', new=io.StringIO()) as fake_stdout:\n",
    "            self.grading_config._setup_environment(None)\n",
    "            self.assertEqual(fake_stdout.getvalue().strip(), 'Please upload a zip file.')\n",
    "        self.assertEqual(self.grading_config.status_output.outputs[0]['text'], 'Please upload a zip file.')\n",
    "\n",
    "    def test_setup_environment_invalid_file(self):\n",
    "        self.grading_config.file_upload.value = {'invalid_file': {'content': b'invalid content'}}\n",
    "        with patch('sys.stdout', new=io.StringIO()) as fake_stdout:\n",
    "            self.grading_config._setup_environment(None)\n",
    "            self.assertEqual(fake_stdout.getvalue().strip(), 'Loading zip file...')\n",
    "        self.assertEqual(self.grading_config.status_output.outputs[0]['text'], 'Loading zip file...\\n')\n",
    "\n",
    "    def test_setup_environment_valid_file(self):\n",
    "        self.grading_config.file_upload.value = {'valid_file.zip': {'content': b'valid zip content'}}\n",
    "        with patch('sys.stdout', new=io.StringIO()) as fake_stdout:\n",
    "            self.grading_config._setup_environment(None)\n",
    "            self.assertEqual(fake_stdout.getvalue().strip(), 'Loading zip file...\\nExtracted files and directories: valid_file.json\\nLoading successful!\\nLearning Objectives: \\nExtracted JSON files: valid_file.json')\n",
    "        self.assertEqual(self.grading_config.status_output.outputs[0]['text'], 'Loading zip file...\\nExtracted files and directories: valid_file.json\\nLoading successful!\\nLearning Objectives: \\nExtracted JSON files: valid_file.json')\n",
    "\n",
    "    def test_run_ui_container(self):\n",
    "        with patch('IPython.display.display') as mock_display:\n",
    "            self.grading_config.run_ui_container()\n",
    "            mock_display.assert_called_once_with(self.grading_config.ui_container, clear=True)\n",
    "\n",
    "    def tearDown(self):\n",
    "        del self.grading_config\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set_css`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "def set_css():\n",
    "  display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for `set_css`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set_css() test passed.\n"
     ]
    }
   ],
   "source": [
    "def test_set_css():\n",
    "    try:\n",
    "        set_css()\n",
    "        print(\"set_css() test passed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"set_css() test failed: {e}\")\n",
    "\n",
    "test_set_css()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`clean_keys`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "def clean_keys(data):\n",
    "    cleaned_data = []\n",
    "    for item in data:\n",
    "        cleaned_item = {}\n",
    "        for key, value in item.items():\n",
    "            cleaned_key = key.strip()\n",
    "            cleaned_value = value.strip() if isinstance(value, str) else value\n",
    "            cleaned_item[cleaned_key] = cleaned_value\n",
    "        cleaned_data.append(cleaned_item)\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for `clean_keys`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_clean_keys():\n",
    "    # Test with a single dictionary\n",
    "    input_data = [{\" foo \": \" bar \", \" baz \": \" qux \"}]\n",
    "    expected_output = [{\"foo\": \"bar\", \"baz\": \"qux\"}]\n",
    "    assert clean_keys(input_data) == expected_output\n",
    "\n",
    "    # Test with multiple dictionaries\n",
    "    input_data = [\n",
    "        {\" foo \": \" bar \", \" baz \": \" qux \"},\n",
    "        {\" spam \": \" eggs \", \" ham \": \" bacon \"},\n",
    "    ]\n",
    "    expected_output = [\n",
    "        {\"foo\": \"bar\", \"baz\": \"qux\"},\n",
    "        {\"spam\": \"eggs\", \"ham\": \"bacon\"},\n",
    "    ]\n",
    "    assert clean_keys(input_data) == expected_output\n",
    "\n",
    "    # Test with empty input\n",
    "    input_data = []\n",
    "    expected_output = []\n",
    "    assert clean_keys(input_data) == expected_output\n",
    "\n",
    "    # Test with input that is not a list of dictionaries\n",
    "    input_data = \"not a list of dictionaries\"\n",
    "    try:\n",
    "        clean_keys(input_data)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    else:\n",
    "        raise AssertionError(\"Expected AttributeError to be raised\")\n",
    "    \n",
    "test_clean_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`file_upload_json_to_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "def file_upload_json_to_df(upload_json):\n",
    "\n",
    "  #get middle key of json to extract content\n",
    "  fname = list(upload_json.keys())[0]\n",
    "\n",
    "  #load the json; strict allows us to get around encoding issues\n",
    "  loaded_json = json.loads(upload_json[fname]['content'], strict=False)\n",
    "\n",
    "  #clean the keys if needed\n",
    "  loaded_json = clean_keys(loaded_json)\n",
    "\n",
    "  return pd.DataFrame(loaded_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for `file_upload_json_to_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_file_upload_json_to_df():\n",
    "    # Test case 1: Test with a simple JSON file\n",
    "    test_json = {\"data.json\": {\"content\": '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}'}}\n",
    "    expected_output = pd.DataFrame({\"name\": [\"John\"], \"age\": [30], \"city\": [\"New York\"]})\n",
    "    assert file_upload_json_to_df(test_json).equals(expected_output)\n",
    "\n",
    "    # Test case 2: Test with a JSON file containing nested objects\n",
    "    test_json = {\"data.json\": {\"content\": '{\"name\": \"John\", \"age\": 30, \"address\": {\"city\": \"New York\", \"state\": \"NY\"}}'}}\n",
    "    expected_output = pd.DataFrame({\"name\": [\"John\"], \"age\": [30], \"address_city\": [\"New York\"], \"address_state\": [\"NY\"]})\n",
    "    assert file_upload_json_to_df(test_json).equals(expected_output)\n",
    "\n",
    "    # Test case 3: Test with a JSON file containing an array of objects\n",
    "    test_json = {\"data.json\": {\"content\": '[{\"name\": \"John\", \"age\": 30}, {\"name\": \"Jane\", \"age\": 25}]'}}\n",
    "    expected_output = pd.DataFrame({\"name\": [\"John\", \"Jane\"], \"age\": [30, 25]})\n",
    "    assert file_upload_json_to_df(test_json).equals(expected_output)\n",
    "\n",
    "    # Test case 4: Test with a JSON file containing an array of nested objects\n",
    "    test_json = {\"data.json\": {\"content\": '[{\"name\": \"John\", \"age\": 30, \"address\": {\"city\": \"New York\", \"state\": \"NY\"}}, {\"name\": \"Jane\", \"age\": 25, \"address\": {\"city\": \"San Francisco\", \"state\": \"CA\"}}]'}}\n",
    "    expected_output = pd.DataFrame({\"name\": [\"John\", \"Jane\"], \"age\": [30, 25], \"address_city\": [\"New York\", \"San Francisco\"], \"address_state\": [\"NY\", \"CA\"]})\n",
    "    assert file_upload_json_to_df(test_json).equals(expected_output)\n",
    "\n",
    "    # Test case 5: Test with a JSON file containing an array of objects with different keys\n",
    "    test_json = {\"data.json\": {\"content\": '[{\"name\": \"John\", \"age\": 30}, {\"name\": \"Jane\", \"city\": \"San Francisco\"}]'}}\n",
    "    expected_output = pd.DataFrame({\"name\": [\"John\", \"Jane\"], \"age\": [30, None], \"city\": [None, \"San Francisco\"]})\n",
    "    assert file_upload_json_to_df(test_json).equals(expected_output)\n",
    "\n",
    "test_file_upload_json_to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_json_as_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "def load_json_as_df(fpath):\n",
    "    # check if file is .json\n",
    "    if not fpath.endswith('.json'):\n",
    "        return None\n",
    "\n",
    "    keys = [\"timestamp\", \"author\", \"message\"]\n",
    "\n",
    "    df_out = None\n",
    "    out_error = None\n",
    "\n",
    "    try:\n",
    "        # Read JSON file\n",
    "        with open(fpath, \"r\") as f:\n",
    "            json_data = f.read()\n",
    "\n",
    "        # Load JSON data\n",
    "        data = json.loads(json_data, strict=False)\n",
    "\n",
    "        # Quick check to see if we can fix common errors in json\n",
    "        # 1. JSON responses wrapped in enclosing dictionary\n",
    "        if isinstance(data, dict):\n",
    "          if len(data.keys()) == 1:\n",
    "            data = data[list(data.keys())[0]]\n",
    "          else:\n",
    "            data = [data] #convert to list otherwise\n",
    "\n",
    "        # We only operate on lists of dictionaries\n",
    "        if isinstance(data, list):\n",
    "          data = clean_keys(data) #clean keys to make sure there are no unnecessary newlines\n",
    "\n",
    "          if all(all(k in d for k in keys) for d in data):\n",
    "              df_out = pd.json_normalize(data)\n",
    "              if len(df_out) <=1:\n",
    "                out_error = [fpath, \"Warning: JSON keys correct, but something wrong with the overall structure of the JSON when converting to dataframe. The dataframe only has one row. Skipping.\"]\n",
    "                df_out = None\n",
    "          else:\n",
    "              out_error = [fpath, \"Error: JSON Keys are incorrect. Found keys: \" + str(list(data[0].keys()))]\n",
    "        else:\n",
    "            out_error = [fpath, \"Error: Something is wrong with the structure of the JSON.\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {fpath}: {str(e)}\")\n",
    "        out_error = [fpath, \"Fatal System Error: \"+str(e)]\n",
    "\n",
    "    if df_out is not None:\n",
    "        df_out['filename'] = fpath\n",
    "\n",
    "    return df_out, out_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for `load_json_as_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_as_df(fpath):\n",
    "    # check if file is .json\n",
    "    if not fpath.endswith('.json'):\n",
    "        return None\n",
    "\n",
    "    keys = [\"timestamp\", \"author\", \"message\"]\n",
    "\n",
    "    df_out = None\n",
    "    out_error = None\n",
    "\n",
    "    try:\n",
    "        # Read JSON file\n",
    "        with open(fpath, \"r\") as f:\n",
    "            json_data = f.read()\n",
    "\n",
    "        # Load JSON data\n",
    "        data = json.loads(json_data, strict=False)\n",
    "\n",
    "        # Quick check to see if we can fix common errors in json\n",
    "        # 1. JSON responses wrapped in enclosing dictionary\n",
    "        if isinstance(data, dict):\n",
    "          if len(data.keys()) == 1:\n",
    "            data = data[list(data.keys())[0]]\n",
    "          else:\n",
    "            data = [data] #convert to list otherwise\n",
    "\n",
    "        # We only operate on lists of dictionaries\n",
    "        if isinstance(data, list):\n",
    "          data = clean_keys(data) #clean keys to make sure there are no unnecessary newlines\n",
    "\n",
    "          if all(all(k in d for k in keys) for d in data):\n",
    "              df_out = pd.json_normalize(data)\n",
    "              if len(df_out) <=1:\n",
    "                out_error = [fpath, \"Warning: JSON keys correct, but something wrong with the overall structure of the JSON when converting to dataframe. The dataframe only has one row. Skipping.\"]\n",
    "                df_out = None\n",
    "          else:\n",
    "              out_error = [fpath, \"Error: JSON Keys are incorrect. Found keys: \" + str(list(data[0].keys()))]\n",
    "        else:\n",
    "            out_error = [fpath, \"Error: Something is wrong with the structure of the JSON.\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {fpath}: {str(e)}\")\n",
    "        out_error = [fpath, \"Fatal System Error: \"+str(e)]\n",
    "\n",
    "    if df_out is not None:\n",
    "        df_out['filename'] = fpath\n",
    "\n",
    "    return df_out, out_error\n",
    "\n",
    "def test_load_json_as_df():\n",
    "    # Create a temporary JSON file\n",
    "    data = [\n",
    "        {\"timestamp\": \"2022-01-01 00:00:00\", \"author\": \"Alice\", \"message\": \"Hello\"},\n",
    "        {\"timestamp\": \"2022-01-01 00:01:00\", \"author\": \"Bob\", \"message\": \"Hi there\"},\n",
    "    ]\n",
    "    fpath = \"test.json\"\n",
    "    with open(fpath, \"w\") as f:\n",
    "        f.write(json.dumps(data))\n",
    "\n",
    "    # Call the function\n",
    "    df, error = load_json_as_df(fpath)\n",
    "\n",
    "    # Check the output\n",
    "    assert isinstance(df, pd.DataFrame)\n",
    "    assert len(df) == 2\n",
    "    assert set(df.columns) == set([\"timestamp\", \"author\", \"message\", \"filename\"])\n",
    "    assert df.iloc[0][\"timestamp\"] == \"2022-01-01 00:00:00\"\n",
    "    assert df.iloc[1][\"author\"] == \"Bob\"\n",
    "    assert df.iloc[0][\"filename\"] == fpath\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(fpath)\n",
    "\n",
    "test_load_json_as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pretty_print`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "def pretty_print(df):\n",
    "    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for `pretty_print`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pretty_print():\n",
    "    df = pd.DataFrame({\n",
    "        'name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'grade': [80, 90, 85]\n",
    "    })\n",
    "\n",
    "    result_output = pretty_print(df)\n",
    "\n",
    "    assert result_output != '', 'Output string is empty'\n",
    "\n",
    "test_pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`save_as_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_as_csv(df, file_name):\n",
    "  df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for `save_as_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_save_as_csv():\n",
    "    df = pd.DataFrame({\n",
    "        'name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'grade': [80, 90, 85]\n",
    "    })\n",
    "    file_name = 'test.csv'\n",
    "\n",
    "    save_as_csv(df, file_name)\n",
    "\n",
    "    assert os.path.exists(file_name), 'File does not exist'\n",
    "\n",
    "    os.remove(file_name)\n",
    "\n",
    "test_save_as_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_json_loading_errors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| export\n",
    "def show_json_loading_errors(err_list):\n",
    "  if err_list:\n",
    "    print(\"The following files have the following errors upon loading and will NOT be processed:\", '\\n'.join(err_list))\n",
    "  else:\n",
    "    print(\"No errors found in uploaded zip JSON files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for `show_json_loading_errors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def test_show_json_loading_errors():\n",
    "    err_list = ['file1.json', 'file2.json']\n",
    "    expected_output = 'The following files have the following errors upon loading and will NOT be processed: file1.json\\nfile2.json\\n'\n",
    "\n",
    "    captured_output = io.StringIO()\n",
    "    sys.stdout = captured_output\n",
    "\n",
    "    show_json_loading_errors(err_list)\n",
    "\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "    assert captured_output.getvalue() == expected_output, 'Output string is incorrect'\n",
    "\n",
    "test_show_json_loading_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "default_ai_assisted_setup = output_setup = (\"Given the following chat log, create a table with the question number, the question content, answer, \"\n",
    "                  \"whether or not the student answered correctly on the first try, and the number of attempts it took to get the right answer. \")\n",
    "\n",
    "default_ai_assisted_grading_instructions = (\"Then, calculate the quiz grade from the total number of assessment questions. \"\n",
    "                  \"Importantly, a point should only be granted if an answer was correct on the very first attempt. \"\n",
    "                  \"If an answer was not correct on the first attempt, even if it was correct in subsequent attempts, no point should be awarded for that question. \")\n",
    "\n",
    "bloom_assisted_output_setup = None\n",
    "\n",
    "bloom_assistedgrading_instructions = \"\"\"\\nEvaluate the student's overall level or engagement and knowledge, based on bloom's taxonomy using their responses.\n",
    "Bloom's taxonomy is rated on a 1-6 point system, with 1 being remember (recall facts and basic concepts), 2 being understand (explain ideas or concepts),\n",
    "3 being apply (use information in new situations), 4 being analyze (draw connections among ideas), 5 being evaluate (justify a stand or decision),\n",
    "and 6 being create (produce new or original work). Assign the interaction a score from 1-6, where 1 = remember, 2 = understand, 3 = apply, 4 = analyze,\n",
    "5 = evaluate, and 6 = create.\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
