{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Chat Interface\n",
    "> A standard, baseline, direct implementation of the \"basic user interface\". \n",
    "\n",
    "In this notebook, we create the simplest baseline implementation of the \"basic user interface\". The chat is implemented directly through langchain/openAI, where the prompt is directly input into langchain instead of using the ai_classroom_suite module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this code only if you're local and developing\n",
    "import os, sys\n",
    "\n",
    "# get parent of current working directory\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "#append to path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface Helpers and Functionality\n",
    "\n",
    "In the next section, we'll create some helper functions to make sure we're able to create the interface we want, and that it behaves nicely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "\n",
    "# The OpenAI API key provided by the instructor\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Instructor's prompt (invisible to students)\n",
    "instructor_prompt = os.environ.get(\"SECRET_PROMPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "\n",
    "# Adds a message from the user to the conversation history\n",
    "def add_user_message(msg, history, messages):\n",
    "    messages.append({\"role\": \"user\", \"content\": msg})\n",
    "    return \"\", history + [[msg, None]], messages\n",
    "\n",
    "# Generate a response from the chatbot\n",
    "def get_tutor_reply(history, messages):\n",
    "    completion = openai.chat.completions.create( \n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=150 # Change this \n",
    "    ) \n",
    "    # Extract the model's reply\n",
    "    reply = completion.choices[0].message.content \n",
    "    # Updates the conversation history with the chatbot's response\n",
    "    history[-1][1] = reply\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return history, messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "\n",
    "# Saves the conversation history to a JSON file.\n",
    "def save_chat_to_json(history):\n",
    "    formatted_convo = pd.DataFrame(history, columns=['user', 'chatbot'])\n",
    "    output_fname = f'tutoring_conversation.json'\n",
    "    formatted_convo.to_json(output_fname, orient='records')\n",
    "    return gr.update(value=output_fname, visible=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The User Interface\n",
    "\n",
    "Below, we put all of this information together with the actual formatting of the user interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note for Instructors ###\n",
    "\n",
    "You need to provide an OpenAI API Key as well as a Secret Prompt to initialize the model. \n",
    "\n",
    "- To set the API Key, in the hosted app on Huggingface Space, go to ``Settings -> Variables and Secrets -> Secrets``, then replace ``OPENAI_API_KEY`` value with your key.\n",
    "If you haven't created one already, visit [platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys) to sign up for an account and get your personal API key. \n",
    "\n",
    "- To set the Secret Prompt, in the hosted app on Huggingface Space, go to ``Settings -> Variables and Secrets -> Secrets``, then replace ``SECRET_PROMPT`` value with your key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "\n",
    "### User Interfaces ###\n",
    "with gr.Blocks() as SimpleChat:\n",
    "    gr.Markdown(\"\"\"\n",
    "        ## Chat with A Tutor\n",
    "        Description here\n",
    "        \"\"\")\n",
    "    \n",
    "    # Initialize the model with system message given by the instructor prompt\n",
    "    system_msg = [{\"role\": \"system\", \"content\":  instructor_prompt}]\n",
    "    messages = gr.JSON(visible=False, value = system_msg)\n",
    "    \n",
    "    with gr.Group():\n",
    "        chatbot = gr.Chatbot(label=\"Simple Tutor\")\n",
    "        with gr.Row(equal_height=True):\n",
    "            user_chat_input = gr.Textbox(show_label=False, scale=9)\n",
    "            submit_btn = gr.Button(\"Enter\", scale=1)\n",
    "    with gr.Group():\n",
    "        export_dialogue_button_json = gr.Button(\"Export your chat history as a .json file\")\n",
    "        file_download = gr.Files(label=\"Download here\", file_types=['.json'], visible=False)\n",
    "    \n",
    "    # User submits a message by either click the submit button or press enter on keyboard\n",
    "    submit_btn.click(\n",
    "        fn=add_user_message, inputs=[user_chat_input, chatbot, messages], outputs=[user_chat_input, chatbot, messages], queue=False\n",
    "    ).then(\n",
    "        fn=get_tutor_reply, inputs=[chatbot, messages], outputs=[chatbot, messages], queue=True\n",
    "    )\n",
    "    user_chat_input.submit(\n",
    "        fn=add_user_message, inputs=[user_chat_input, chatbot, messages], outputs=[user_chat_input, chatbot, messages], queue=False\n",
    "    ).then(\n",
    "        fn=get_tutor_reply, inputs=[chatbot, messages], outputs=[chatbot, messages], queue=True\n",
    "    )\n",
    "    export_dialogue_button_json.click(save_chat_to_json, chatbot, file_download, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "SimpleChat.queue().launch(server_name='0.0.0.0', server_port=7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little helper in case your ports are open and you just want to close them all. If this doesn't work, restart your IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
