{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocher Reading Quiz\n",
    "> Creating the reading quiz gradio app with state, reading list, vector store, chat, and chat download.\n",
    "\n",
    "In this notebook, we add the reading list and vector store creating to the basic interaction app to be deployed onto Huggingface Space, which has the following components: \n",
    "\n",
    "- Readings:\n",
    "    Display a list of readings uploaded by professor. \n",
    "- Student interface: \n",
    "    A chat interface where students interact with the chatbot that has had the instructor-designed prompt given to it but they cannot see the prompt. At the end of the conversation, entire convo is made available as downloadable JSON such that students can download it and turn it in to Brightspace."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ReadingQuiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll start by loading our own libraries. Keep in mind that if you're on Colab, you need to replace \"token\" below with your GitHub token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code only if you're using Google Colab\n",
    "#! pip install pip install git+https://ghusername:<token>@github.com/vanderbilt-data-science/lo-achievement.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this code only if you're local and developing\n",
    "import os, sys\n",
    "\n",
    "# get parent of current working directory's parent (we're quite nested)\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# append to path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/lo-achievement/ai_classroom_suite/UIBaseComponents.py:354: GradioUnusedKwargWarning: You have unused kwarg parameters in Box, please remove them: {'scale': 1}\n",
      "  with gr.Box(elem_id=\"sources-container\", scale=1):\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import os\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from ai_classroom_suite.MediaVectorStores import *\n",
    "from ai_classroom_suite.UIBaseComponents import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface Helpers and Functionality\n",
    "\n",
    "In the next section, we'll create some helper functions to make sure we're able to create the interface we want, and that it behaves nicely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Store Functions\n",
    "\n",
    "In this section, we define several functions related to creating vectore store from a folder of files and write the vector store to file.\n",
    "\n",
    "- Default values:\n",
    "    - The default folder path is \"context_files/\" \n",
    "    - The default output file name is \"vector_store.txt\"\n",
    "- vector_store_file_exist()\n",
    "    - Check if the output vector store file already exists in the folder. \n",
    "- get_filepathts_from_filder(fold_path)\n",
    "    - This function get all the files' paths from a specified folder. \n",
    "- write_vector_store_to_file(out_file_name, vs_button)\n",
    "    - This function creates the vector store of a given list of files and writes that into output file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "#  default folder path\n",
    "folder_path = \"context_files\"\n",
    "#  default output file name\n",
    "out_file_name = \"vector_store.txt\"\n",
    "\n",
    "# Check if vector store file already exist on disk\n",
    "def vector_store_file_exist():\n",
    "    # Get all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Check if output file already exist in this folder\n",
    "    return (out_file_name in files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "# Helper function to get all files' paths from a folder\n",
    "# Return a list of file paths except for README.txt and vector_store.txt (if exist)\n",
    "def get_filepaths_from_folder(folder_path):\n",
    "    # Store the paths of files\n",
    "    filepath_list = []\n",
    "    \n",
    "    # Check if the specified folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder '{folder_path}' does not exist.\")\n",
    "        return filepath_list\n",
    "    \n",
    "    # Get all the files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    for file_name in files:\n",
    "        # Excluding README.txt and vector_store.txt\n",
    "        if file_name != \"README.txt\" and file_name != \"vector_store.txt\":\n",
    "            # Get the file path for each item\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            # Check if the item is a file and not a subdirectory\n",
    "            if os.path.isfile(file_path):\n",
    "                filepath_list.append(file_path)\n",
    "    \n",
    "    return filepath_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "# Helper function to write content of files in a folder to output file\n",
    "def write_vector_store_to_file(out_file_name):\n",
    "    # If vector_store.txt already exist, return nothing\n",
    "    if vector_store_file_exist():\n",
    "        return gr.File(value=out_file_name, visible=False)\n",
    " \n",
    "    # Only try to create the vector store if vector_store.txt doesn't exist\n",
    "    else:\n",
    "        # Call the function to read files (excluding README.txt and vector_store.txt) pathes\n",
    "        filepath_list = get_filepaths_from_folder(folder_path)\n",
    "        # Extract the text out from files\n",
    "        files_content = files_to_text(filepath_list, chunk_size=100, chunk_overlap=20)\n",
    "        \n",
    "        # Write the vector_store onto the output file\n",
    "        with open(out_file_name, \"w\") as f:\n",
    "            for i in range(len(files_content)):\n",
    "                item = str(files_content[i]) + \"\\n\"\n",
    "                f.write(item)\n",
    "        \n",
    "        # Show the downlodable vector store file and give instruction on upload the vector store file to disk (on HuggingFace)\n",
    "        return gr.File(title=\"Download your vector store file and upload it into the context_files folder under Files\", \n",
    "                       value=out_file_name, visible=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The User Interface\n",
    "\n",
    "Below, we put all of this information together with the actual formatting of the user interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note for Instructors ###\n",
    "\n",
    "1. Provide an OpenAI API Key\n",
    "- To set the API Key, in the hosted app on Huggingface Space, go to ``Settings -> Variables and Secrets -> Secrets``, then replace ``OPENAI_API_KEY`` value with your key.\n",
    "- If you haven't created one already, visit [platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys) to sign up for an account and get your personal API key. \n",
    "2. Provide a Secret Prompt \n",
    "- To set the Secret Prompt, in the hosted app on Huggingface Space, go to ``Settings -> Variables and Secrets -> Secrets``, then replace ``SECRET_PROMPT`` value with your prompt.\n",
    "3. Upload files into vector store\n",
    "- On Hugging Face Space, in ``Files`` Section, there's already a folder called ``context_files`` already created for you. \n",
    "- **Don't delete the file called ``README.txt``** as it is used to keep the ``context_files`` folder exist. You can change the content of that. It will not be read into the vector store. \n",
    "- You can delete or upload any other files you like into this ``context_files`` folder, and these will be read into the vector store.\n",
    "- The final vector store file called ``vector_store.txt`` will be stored in this ``context_files`` folder as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function for Button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "# To show the loading process on the button when creating vector store file\n",
    "def creating_vs_button(obj_in):\n",
    "    return gr.update(interactive=False, value='Creating Vector Store file...')\n",
    "# To show the loading process on the button when initializing tutor\n",
    "def initializing_tutor_button(obj_in):\n",
    "    return gr.update(interactive=False, value='Initializing Tutor...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "# overwrites the original method since we don't deal with any vector stores display here\n",
    "def get_tutor_reply(chat_tutor):\n",
    "    chat_tutor.get_tutor_reply()\n",
    "    return gr.update(value=\"\", interactive=True), chat_tutor.conversation_memory, chat_tutor\n",
    "\n",
    "def get_conversation_history(chat_tutor):\n",
    "    return chat_tutor.conversation_memory, chat_tutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| to_script\n",
    "with gr.Blocks() as ReadingQuiz:\n",
    "    #initialize tutor (with state)\n",
    "    study_tutor = gr.State(SlightlyDelusionalTutor())\n",
    "\n",
    "    # Student chatbot interface\n",
    "    gr.Markdown(\"\"\"\n",
    "    ## Chat with the Model\n",
    "    Description here\n",
    "    \"\"\")\n",
    "    \n",
    "    # Instead of ask students to provide key, the key is now provided by the instructor. \n",
    "    api_input = gr.Textbox(show_label=False, type=\"password\", visible=False, value=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    # The instructor will provide a secret prompt/persona to the tutor\n",
    "    instructor_prompt = gr.Textbox(label=\"Verify your prompt content\", value = os.environ.get(\"SECRET_PROMPT\"), visible=False)\n",
    "    \n",
    "    # Show input files\n",
    "    file_input = gr.File(label=\"Reading materials\", value=get_filepaths_from_folder(folder_path), visible=True)\n",
    "    \n",
    "    # Show output file for vector store when needed\n",
    "    vs_file_name = gr.Text(visible=False, value=out_file_name)\n",
    "    file_output = gr.File(visible=False)\n",
    "    \n",
    "    # Placeholders components\n",
    "    text_input_none = gr.Textbox(visible=False)\n",
    "    file_input_none = gr.File(visible=False)\n",
    "    instructor_input_none = gr.TextArea(visible=False)\n",
    "    learning_objectives_none = gr.Textbox(visible=False)\n",
    "\n",
    "    # Set the secret prompt in this session and embed it to the study tutor\n",
    "    vs_build_button = gr.Button(\"Initialize Tutor\")\n",
    "    vs_build_button.click(\n",
    "        fn=creating_vs_button, inputs=vs_build_button, outputs=vs_build_button\n",
    "    ).then(\n",
    "        fn=write_vector_store_to_file, inputs=[vs_file_name], outputs=[file_output]\n",
    "    ).then(\n",
    "        fn=initializing_tutor_button, inputs=[vs_build_button], outputs=[vs_build_button]\n",
    "    ).then(\n",
    "        fn=create_reference_store, \n",
    "        inputs=[study_tutor, vs_build_button, instructor_prompt, file_output, instructor_input_none, api_input, learning_objectives_none],\n",
    "        outputs=[study_tutor, vs_build_button]\n",
    "    )\n",
    "\n",
    "    with gr.Row(equal_height=True):\n",
    "        with gr.Column(scale=2):\n",
    "            chatbot = gr.Chatbot()\n",
    "            with gr.Row():\n",
    "                user_chat_input = gr.Textbox(label=\"User input\", scale=9)\n",
    "                user_chat_submit = gr.Button(\"Ask/answer model\", scale=1)\n",
    "\n",
    "    # First add user's message to the conversation history\n",
    "    # Then get reply from the tutor and add that to the conversation history\n",
    "    user_chat_submit.click(\n",
    "        fn = add_user_message, inputs = [user_chat_input, study_tutor], outputs = [user_chat_input, chatbot, study_tutor], queue=False\n",
    "    ).then(\n",
    "        fn = get_tutor_reply, inputs = [study_tutor], outputs = [user_chat_input, chatbot, study_tutor], queue=True\n",
    "    )\n",
    "    # User can also press \"Enter\" on keyboard to submit a message\n",
    "    user_chat_input.submit(\n",
    "        fn = add_user_message, inputs = [user_chat_input, study_tutor], outputs = [user_chat_input, chatbot, study_tutor], queue=False\n",
    "    ).then(\n",
    "        fn = get_tutor_reply, inputs = [study_tutor], outputs = [user_chat_input, chatbot, study_tutor], queue=True\n",
    "    )\n",
    "\n",
    "    # Download conversation history file\n",
    "    with gr.Blocks():\n",
    "        gr.Markdown(\"\"\"\n",
    "        ## Export Your Chat History\n",
    "        Export your chat history as a .json, .txt, or .csv file\n",
    "        \"\"\")\n",
    "        with gr.Row():\n",
    "            export_dialogue_button_json = gr.Button(\"JSON\")\n",
    "            export_dialogue_button_txt = gr.Button(\"TXT\")\n",
    "            export_dialogue_button_csv = gr.Button(\"CSV\")\n",
    "            \n",
    "        file_download = gr.Files(label=\"Download here\", file_types=['.json', '.txt', '.csv'], type=\"file\", visible=False)\n",
    "    \n",
    "    export_dialogue_button_json.click(save_json, study_tutor, file_download, show_progress=True)\n",
    "    export_dialogue_button_txt.click(save_txt, study_tutor, file_download, show_progress=True)\n",
    "    export_dialogue_button_csv.click(save_csv, study_tutor, file_download, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gradio/helpers.py:818: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Textbox(...)` instead of `return gr.update(...)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/components/button.py:89: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Button(...)` instead of `return gr.Button.update(...)`.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.10/asyncio/runners.py:44: GradioUnusedKwargWarning: You have unused kwarg parameters in File, please remove them: {'title': 'Download your vector store file and upload it into the context_files folder under Files'}\n",
      "  return loop.run_until_complete(main)\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/helpers.py:818: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Textbox(...)` instead of `return gr.update(...)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/components/button.py:89: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Button(...)` instead of `return gr.Button.update(...)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just got called.\n",
      "<tempfile._TemporaryFileWrapper object at 0x7f30e432b670>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 388, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 217, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1553, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1191, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 659, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/UIBaseComponents.py\", line 202, in create_reference_store\n",
      "    upload_segs = get_document_segments(upload_fnames, 'file', chunk_size=700, chunk_overlap=100)\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/MediaVectorStores.py\", line 163, in get_document_segments\n",
      "    doc_segments = load_fcn(context_info, **addtnl_params)\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/MediaVectorStores.py\", line 69, in files_to_text\n",
      "    all_segments = list(itertools.chain(*all_segments)) if isinstance(all_segments[0], list) else all_segments\n",
      "IndexError: list index out of range\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/components/textbox.py:163: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Textbox(...)` instead of `return gr.Textbox.update(...)`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 388, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 217, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1553, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1191, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 659, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_68370/70865877.py\", line 4, in get_tutor_reply\n",
      "    chat_tutor.get_tutor_reply()\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/UIBaseComponents.py\", line 118, in get_tutor_reply\n",
      "    tutor_message = get_tutoring_answer('The following is the history of our conversation:\\n\\n' + self.flattened_conversation,\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/PromptInteractionBase.py\", line 151, in get_tutoring_answer\n",
      "    raise NotImplementedError(f\"tutor_mdl of type {type(tutor_mdl)} is not supported.\")\n",
      "NotImplementedError: tutor_mdl of type <class 'NoneType'> is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReadingQuiz.queue().launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/lo-achievement/Apps/ui_nbs/BlocherReadingQuiz.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f62656c6c6373312f446f63756d656e74732f6473692f6473692d70726f6a656374732f7532332d647373672f6c6f2d616368696576656d656e74222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f62656c6c6373312f446f63756d656e74732f6473692f6473692d70726f6a656374732f7532332d647373672f6c6f2d616368696576656d656e742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f62656c6c6373312f446f63756d656e74732f6473692f6473692d70726f6a656374732f7532332d647373672f6c6f2d616368696576656d656e742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f62656c6c6373312f446f63756d656e74732f6473692f6473692d70726f6a656374732f7532332d647373672f6c6f2d616368696576656d656e742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/lo-achievement/Apps/ui_nbs/BlocherReadingQuiz.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#| to_script\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f55736572732f62656c6c6373312f446f63756d656e74732f6473692f6473692d70726f6a656374732f7532332d647373672f6c6f2d616368696576656d656e74222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22636f6e74657874223a226465736b746f702d6c696e7578227d2c22636f6e66696746696c65223a7b22246d6964223a312c22667350617468223a222f55736572732f62656c6c6373312f446f63756d656e74732f6473692f6473692d70726f6a656374732f7532332d647373672f6c6f2d616368696576656d656e742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2265787465726e616c223a2266696c653a2f2f2f55736572732f62656c6c6373312f446f63756d656e74732f6473692f6473692d70726f6a656374732f7532332d647373672f6c6f2d616368696576656d656e742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c2270617468223a222f55736572732f62656c6c6373312f446f63756d656e74732f6473692f6473692d70726f6a656374732f7532332d647373672f6c6f2d616368696576656d656e742f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a2266696c65227d7d/workspaces/lo-achievement/Apps/ui_nbs/BlocherReadingQuiz.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m ReadingQuiz\u001b[39m.\u001b[39;49mqueue()\u001b[39m.\u001b[39;49mlaunch(server_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m0.0.0.0\u001b[39;49m\u001b[39m'\u001b[39;49m, server_port\u001b[39m=\u001b[39;49m\u001b[39m7860\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:2037\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, file_directories, allowed_paths, blocked_paths, root_path, _frontend, app_kwargs, state_session_capacity)\u001b[0m\n\u001b[1;32m   2029\u001b[0m     wasm_utils\u001b[39m.\u001b[39mregister_app(app)\n\u001b[1;32m   2030\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2031\u001b[0m     (\n\u001b[1;32m   2032\u001b[0m         server_name,\n\u001b[1;32m   2033\u001b[0m         server_port,\n\u001b[1;32m   2034\u001b[0m         local_url,\n\u001b[1;32m   2035\u001b[0m         app,\n\u001b[1;32m   2036\u001b[0m         server,\n\u001b[0;32m-> 2037\u001b[0m     ) \u001b[39m=\u001b[39m networking\u001b[39m.\u001b[39;49mstart_server(\n\u001b[1;32m   2038\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2039\u001b[0m         server_name,\n\u001b[1;32m   2040\u001b[0m         server_port,\n\u001b[1;32m   2041\u001b[0m         ssl_keyfile,\n\u001b[1;32m   2042\u001b[0m         ssl_certfile,\n\u001b[1;32m   2043\u001b[0m         ssl_keyfile_password,\n\u001b[1;32m   2044\u001b[0m         app_kwargs\u001b[39m=\u001b[39;49mapp_kwargs,\n\u001b[1;32m   2045\u001b[0m     )\n\u001b[1;32m   2046\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserver_name \u001b[39m=\u001b[39m server_name\n\u001b[1;32m   2047\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_url \u001b[39m=\u001b[39m local_url\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/networking.py:207\u001b[0m, in \u001b[0;36mstart_server\u001b[0;34m(blocks, server_name, server_port, ssl_keyfile, ssl_certfile, ssl_keyfile_password, app_kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot find empty port in range: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmin\u001b[39m(server_ports)\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmax\u001b[39m(server_ports)\u001b[39m}\u001b[39;00m\u001b[39m. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m ssl_keyfile \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     path_to_local_server \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://\u001b[39m\u001b[39m{\u001b[39;00murl_host_name\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39;00mport\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`."
     ]
    }
   ],
   "source": [
    "#| to_script\n",
    "ReadingQuiz.queue().launch(server_name='0.0.0.0', server_port=7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little helper in case your ports are open and you just want to close them all. If this doesn't work, restart your IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
