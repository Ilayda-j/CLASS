{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Featured Self Study App\n",
    "> Working with Generative AI to help you better understand your work\n",
    "\n",
    "This notebook can be opened in Google Colab, and additionally, there is an existing hosted app on Huggingface that you can use if you don't want to use Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code only if you're using Google Colab\n",
    "#! pip install pip install git+https://<token>@github.com/vanderbilt-data-science/lo-achievement.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this code only if you're local and developing\n",
    "import os, sys\n",
    "\n",
    "# get parent of current working directory's parent (we're quite nested)\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# append to path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/lo-achievement/ai_classroom_suite/UIBaseComponents.py:350: GradioUnusedKwargWarning: You have unused kwarg parameters in Box, please remove them: {'scale': 1}\n",
      "  with gr.Box(elem_id=\"sources-container\", scale=1):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gradio/helpers.py:818: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Textbox(...)` instead of `return gr.update(...)\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/components/button.py:89: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Button(...)` instead of `return gr.Button.update(...)`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gradio/components/textbox.py:163: UserWarning: Using the update method is deprecated. Simply return a new object instead, e.g. `return gr.Textbox(...)` instead of `return gr.Textbox.update(...)`.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 388, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 217, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1553, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1191, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 659, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/UIBaseComponents.py\", line 249, in get_tutor_reply\n",
      "    chat_tutor.get_tutor_reply(input_kwargs={'question':learning_topic})\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/UIBaseComponents.py\", line 113, in get_tutor_reply\n",
      "    tutor_message = get_tutoring_answer('The following is the history of our conversation:\\n\\n' + self.flattened_conversation,\n",
      "TypeError: get_tutoring_answer() got an unexpected keyword argument 'chat_history'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just got called.\n",
      "[<tempfile._TemporaryFileWrapper object at 0x7ff5bbc04610>]\n",
      "[Document(page_content='Two roads diverged in a yellow wood,\\rAnd sorry I could not travel both\\rAnd be one traveler, long I stood\\rAnd looked down one as far as I could\\rTo where it bent in the undergrowth;\\r\\rThen took the other, as just as fair,\\rAnd having perhaps the better claim,\\rBecause it was grassy and wanted wear;\\rThough as for that the passing there\\rHad worn them really about the same,\\r\\rAnd both that morning equally lay\\rIn leaves no step had trodden black. Oh, I kept the first for another day! Yet knowing how way leads on to way,\\rI doubted if I should ever come back. I shall be telling this with a sigh\\rSomewhere ages and ages hence:\\rTwo roads diverged in a wood, and IэI took the one less traveled by,\\rAnd that', metadata={'source': '/tmp/gradio/789c7f47c220747b1c7529a884cf98b177586b66/roadnottaken.txt', 'start_index': 0}), Document(page_content='ages and ages hence:\\rTwo roads diverged in a wood, and IэI took the one less traveled by,\\rAnd that has made all the difference.', metadata={'source': '/tmp/gradio/789c7f47c220747b1c7529a884cf98b177586b66/roadnottaken.txt', 'start_index': 600})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 388, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 217, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1553, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1191, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 659, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/UIBaseComponents.py\", line 212, in create_reference_store\n",
      "    chat_tutor = initialize_basic_model(chat_tutor,\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/UIBaseComponents.py\", line 172, in initialize_basic_model\n",
      "    qa_chain = create_tutor_mdl_chain(**mdl_chain_kwargs)\n",
      "  File \"/workspaces/lo-achievement/ai_classroom_suite/PromptInteractionBase.py\", line 192, in create_tutor_mdl_chain\n",
      "    mdl_chain = ConversationalRetrievalChain.from_llm(mdl, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/langchain/chains/conversational_retrieval/base.py\", line 356, in from_llm\n",
      "    return cls(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/langchain/load/serializable.py\", line 90, in __init__\n",
      "    super().__init__(**kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/pydantic/v1/main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 1 validation error for ConversationalRetrievalChain\n",
      "chat_history\n",
      "  extra fields not permitted (type=value_error.extra)\n"
     ]
    }
   ],
   "source": [
    "#| to_script\n",
    "# Import the needed components\n",
    "from ai_classroom_suite.UIBaseComponents import *\n",
    "from ai_classroom_suite.UIBaseComponents import FullStudyApp\n",
    "\n",
    "# Launch the relevant component\n",
    "FullStudyApp.queue().launch(server_name='0.0.0.0', server_port=7860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
