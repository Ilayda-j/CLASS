{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanderbilt-data-science/lo-achievement/blob/146-modify-ui-to-have-two-separate-mechanisms/UI_design_oral_exam_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIbogPXyM0wr"
      },
      "source": [
        "# Project IO Achievement - UI Design (Oral Exam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Vp8SiKM4p1"
      },
      "source": [
        "## Problem Definition\n",
        "\n",
        "We have considered two foundational methods of interacting with the oral exam interface:\n",
        "\n",
        "Presentation Mode (record your entire speech/presentation - GenAI provides feedback)\n",
        "Exam Mode (essentially verbal chat with the GenAI)\n",
        "We should implement this in a really straightforward way for the user to interact with and distinguish between the two approaches. One way to do this is through accordions, where:\n",
        "\n",
        "One accordion reflects presentation mode\n",
        "Another accordion reflects needs for exam mdoe\n",
        "All things that are in common (e.g., chat interaction at the end) should be in one single place. In other words, the accordions just implement whatever is necessary for that specific approach minus the chat part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_60X8H3NEne"
      },
      "source": [
        "## Libraries\n",
        "\n",
        "This section will install and import some important libraries such as Langchain, openai, Gradio, and so on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pxcqXgg2aAN7"
      },
      "outputs": [],
      "source": [
        "# install libraries here\n",
        "# -q flag for \"quiet\" install\n",
        "%%capture\n",
        "!pip install -q langchain\n",
        "!pip install -q openai\n",
        "!pip install -q gradio\n",
        "!pip install -q torchaudio\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q docx\n",
        "!pip install -q PyPDF2\n",
        "!pip install -q python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pEjM1tLsMZBq"
      },
      "outputs": [],
      "source": [
        "# import libraries here\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain import ConversationChain, LLMChain, PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "import openai\n",
        "import os\n",
        "from getpass import getpass\n",
        "import time\n",
        "import requests\n",
        "import whisper\n",
        "import numpy as np\n",
        "import torch\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from docx import Document\n",
        "import PyPDF2\n",
        "from pydub import AudioSegment\n",
        "import tempfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03KLZGI_a5W5"
      },
      "source": [
        "## API Keys\n",
        "\n",
        "Use these cells to load the API keys required for this notebook. The below code cell uses the `getpass` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5smcWj4DbFgy",
        "outputId": "a97eb808-6165-4692-b539-caa5fb7aaba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "openai_api_key = getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "openai.api_key = openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgnCZRMhADvo",
        "outputId": "7cda37a8-d198-476f-ebfc-7721b00bd0e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-4', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "chat = ChatOpenAI(temperature=0.0, model_name='gpt-4')\n",
        "chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMo9x8u4AEV1"
      },
      "source": [
        "## Prompt Design"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chatbot Prompt"
      ],
      "metadata": {
        "id": "2tTNiyU-ZcDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-VmK_7vHrmw",
        "outputId": "1e0c852c-6b8a-4db7-890a-8b24b18ae86c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['history', 'input', 'instruction', 'questions']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "template_string3 = \"\"\"\n",
        "Please ask me the following questions in sequence, and after I provide the answer, \\\n",
        "please give me some feedback. Here is the instruction for feedback: {instruction}. If no instruction is provided, please provide feedback based on your judgement. \\\n",
        "Just ask me the question, and please do not show any other text (no need for greetings for example) \\\n",
        "Here are the questions that you can will me: {questions}. \\\n",
        "Here are the chat history: {history}. \\\n",
        "{input}\n",
        "\n",
        "Once all questions are answered, thank the user and give overall feedback for the question answering part.\n",
        "\"\"\"\n",
        "prompt_template3 = ChatPromptTemplate.from_template(template_string3)\n",
        "prompt_template3.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5vWxcm25EAC"
      },
      "source": [
        "### Prompt for Oral Exam Question Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y95FExV-5IqI"
      },
      "source": [
        "In this example, the context would include the poem \"The Road Not Taken\" by Robert Frost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j_qEXDWQ5RSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c12505-8020-4058-8cf8-d94eca0a4dcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['context', 'pre_prompt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# This is what I used to test the function 'generate_questions_v2'\n",
        "template_string = \"\"\"\n",
        "You are a world-class tutor helping students to perform better on oral and written exams though interactive experiences.\"\n",
        "\n",
        "The following text should be used as the basis for the instructions which follow: {context} \\\n",
        "\n",
        "The following is the guideline for generating the questiion: {pre_prompt} \\\n",
        "\n",
        "The output should be formatted as following:\n",
        "\n",
        "Question 1: ...\n",
        "Question 2: ...\n",
        "Question 3: ...\n",
        "...\n",
        "\"\"\"\n",
        "\n",
        "question_template = ChatPromptTemplate.from_template(template_string)\n",
        "question_template.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt for Presentation Question Generation"
      ],
      "metadata": {
        "id": "G7pwQH8y4Pci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is what I used to test the function 'generate_presentation_questions'\n",
        "prompt_QA = \"\"\"\n",
        "You are a world-class tutor helping students to perform better on oral and written exams though interactive experiences.\"\n",
        "\n",
        "The following text should be used as the basis for the instructions which follow: {context} \\\n",
        "\n",
        "The following text is the transcript of the presentation from the student: {presentation_script}  \\\n",
        "\n",
        "The following is the guideline for generating the questiion: {guideline}; If no guideline is provided, please generate questions based on your judgement \\\n",
        "\n",
        "Based on the presentation, please design 5 follow-up questions based on the context provided and the inputted learning objectives (if applicable).\" \\\n",
        "\n",
        "The output should be formatted as following:\n",
        "\n",
        "Question 1: ...\n",
        "Question 2: ...\n",
        "Question 3: ...\n",
        "...\n",
        "\"\"\"\n",
        "\n",
        "presentation_question_template = ChatPromptTemplate.from_template(prompt_QA)\n",
        "presentation_question_template.messages[0].prompt.input_variables"
      ],
      "metadata": {
        "id": "KDq3Azda4Xc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9d3067-5136-4106-fc3e-f01cbe5361d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['context', 'guideline', 'presentation_script']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMTybR3PVuoC"
      },
      "source": [
        "### Creating a prompt for AI Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wc-3XAFQVxO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7b724e-bf75-49e4-ccb1-e4c0a4583bf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['QA', 'context', 'instructions', 'transcript']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "template_evaluation = \"\"\"\n",
        "Given\n",
        "1. The follwing is the context of the oral exam/presentation: {context} \\\n",
        "\n",
        "2. The answer from the student: {transcript} \\\n",
        "\n",
        "3. The Questions asked to the student and student answers {QA} \\\n",
        "\n",
        "Please evaluate the students performance based on {instructions} \\\n",
        "\n",
        "If no instruction is provided, you can evaluate based on your judgement of the students performance.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "evaluate_template = ChatPromptTemplate.from_template(template_evaluation)\n",
        "evaluate_template.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template_evaluation_oral = \"\"\"\n",
        "Given\n",
        "1. The follwing is the context of the oral exam/presentation: {context} \\\n",
        "\n",
        "2. The Questions asked to the student and student answers {QA} \\\n",
        "\n",
        "Please evaluate the students performance based on {instructions} \\\n",
        "\n",
        "If no instruction is provided, you can evaluate based on your judgement of the students performance.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "evaluate_template_oral = ChatPromptTemplate.from_template(template_evaluation_oral)\n",
        "evaluate_template_oral.messages[0].prompt.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMzIN5IiUTSl",
        "outputId": "41344cf4-6057-4bd2-b294-cd11785c24c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['QA', 'context', 'instructions']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4o8R5eUE1n8"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ABN0X9xQHeii"
      },
      "outputs": [],
      "source": [
        "def embed_key(openai_api_key):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "def transcribe(audio_file_path):\n",
        "  try:\n",
        "    with open(audio_file_path, \"rb\") as audio_file:\n",
        "      # Call OpenAI's Whisper model for transcription\n",
        "      transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "      transcribed_text = transcript[\"text\"]\n",
        "      return transcribed_text\n",
        "  except:\n",
        "    return \"Your answer will be transcribed here\"\n",
        "\n",
        "def process_file(files):\n",
        "  for file in files:\n",
        "    try:\n",
        "        extension = file.name.split('.')[-1].lower()\n",
        "        if extension == 'docx':\n",
        "            doc = Document(file.name)\n",
        "            full_text = []\n",
        "            for paragraph in doc.paragraphs:\n",
        "                full_text.append(paragraph.text)\n",
        "            return '\\n'.join(full_text)\n",
        "\n",
        "        elif extension == 'pdf':\n",
        "            pdf_file = open(file.name, 'rb')\n",
        "            reader = PyPDF2.PdfReader(pdf_file)\n",
        "            num_pages = len(reader.pages)\n",
        "            full_text = []\n",
        "            for page in range(num_pages):\n",
        "                page_obj = reader.pages[page]\n",
        "                full_text.append(page_obj.extract_text())\n",
        "            pdf_file.close()\n",
        "            return '\\n'.join(full_text)\n",
        "\n",
        "        elif extension == 'txt':\n",
        "            with open(file.name, 'r') as txt_file:\n",
        "                full_text = txt_file.read()\n",
        "            return full_text\n",
        "\n",
        "        else:\n",
        "            return \"Unsupported file type\"\n",
        "    except FileNotFoundError:\n",
        "        return \"File not found\"\n",
        "    except PermissionError:\n",
        "        return \"Permission denied\"\n",
        "\n",
        "def generate_questions(text, prompt):\n",
        "    test_input1 = question_template.format_messages(\n",
        "                      context = text,\n",
        "                      pre_prompt = prompt)\n",
        "\n",
        "    response = chat(test_input1)\n",
        "    return response.content\n",
        "\n",
        "def generate_oral_exam_questions(text, prompt):\n",
        "    test_input1 = question_template.format_messages(\n",
        "                      context = text,\n",
        "                      pre_prompt = prompt)\n",
        "\n",
        "    response = chat(test_input1)\n",
        "    return response.content\n",
        "\n",
        "def generate_presentation_questions(text, script, guidelines):\n",
        "    test_input1 = presentation_question_template.format_messages(\n",
        "                      context = text,\n",
        "                      presentation_script = script,\n",
        "                      guideline = guidelines\n",
        "                      )\n",
        "\n",
        "    response = chat(test_input1)\n",
        "    return response.content\n",
        "\n",
        "\n",
        "def ai_evaluate(context, audio_transcript, QA, instructions):\n",
        "    test_input1 = evaluate_template.format_messages(\n",
        "                      context = context,\n",
        "                      transcript = audio_transcript,\n",
        "                      QA = QA,\n",
        "                      instructions = instructions)\n",
        "\n",
        "    response = chat(test_input1)\n",
        "    return response.content\n",
        "\n",
        "def ai_evaluate_oral_exam(context, QA, instructions):\n",
        "    test_input1 = evaluate_template_oral.format_messages(\n",
        "                      context = context,\n",
        "                      QA = QA,\n",
        "                      instructions = instructions)\n",
        "\n",
        "    response = chat(test_input1)\n",
        "    return response.content\n",
        "\n",
        "def upload_file(files):\n",
        "    file_paths = [file.name for file in files]\n",
        "    return file_paths\n",
        "\n",
        "def use_these_questions(input):\n",
        "    return input\n",
        "\n",
        "################################\n",
        "\n",
        "def add_text(history, text, prompt = template_string3):\n",
        "    new_history = [(prompt, None)] + history + [(text, None)]\n",
        "    return new_history, gr.update(value=\"\", interactive=False)\n",
        "\n",
        "# def add_file(history, file):\n",
        "#     history = history + [((file.name,), None)]\n",
        "#     return history\n",
        "\n",
        "\n",
        "def bot_initialize(input, instruction_feedback, questions_used, history):\n",
        "\n",
        "    template_string3 = \"\"\"\n",
        "    Please ask me the following questions in sequence, and after I provide the answer, \\\n",
        "    please give me some feedback. Here is the instruction for feedback: {instruction}. If no instruction is provided, please provide feedback based on your judgement. \\\n",
        "    Here are the questions that you can ask me: {questions}. \\\n",
        "    Here are the chat history: {history}. \\\n",
        "    {input} \\\n",
        "\n",
        "    *** Remember, just ask me the question, give feedbacks, and ask the next questions. Do not forget to ask the next question after feedbacks. \\\n",
        "    \"\"\"\n",
        "    prompt_template3 = ChatPromptTemplate.from_template(template_string3)\n",
        "\n",
        "    test_input1 = prompt_template3.format_messages(\n",
        "                      instruction = instruction_feedback,\n",
        "                      history = history,\n",
        "                      questions = questions_used,\n",
        "                      input = input)\n",
        "\n",
        "    response = chat(test_input1)\n",
        "    return response.content\n",
        "\n",
        "# def initialize(instruction_feedback, questions_used, chat_history, ready):\n",
        "#     test_input1 = prompt_template3.format_messages(\n",
        "#                       instruction = instruction_feedback,\n",
        "#                       chat_history = chat_history,\n",
        "#                       questions = questions_used,\n",
        "#                       ready = ready)\n",
        "#     response = chat(test_input1)\n",
        "#     return response.content\n",
        "\n",
        "# def bot(history):\n",
        "#     response = \"**That's cool!**\"\n",
        "#     history[-1][1] = \"\"\n",
        "#     for character in response:\n",
        "#         history[-1][1] += character\n",
        "#         time.sleep(0.05)\n",
        "#         yield history\n",
        "\n",
        "def message_and_history(input, instruction_feedback, questions_used, history):\n",
        "    history = history or []\n",
        "    s = list(sum(history, ()))\n",
        "    s.append(input)\n",
        "    inp = ' '.join(s)\n",
        "    output = bot_initialize(inp, instruction_feedback, questions_used, history)\n",
        "    history.append((input, output))\n",
        "    return history, history\n",
        "\n",
        "def prompt_select(selection, number, length):\n",
        "  if selection == \"Random\":\n",
        "    prompt = f\"Please design a {number} question quiz based on the context provided and the inputted learning objectives (if applicable).\"\n",
        "  elif selection == \"Fill in the Blank\":\n",
        "    prompt = f\"Create a {number} question fill in the blank quiz refrencing the context provided. The quiz should reflect the learning objectives (if inputted). The 'blank' part of the question should appear as '________'. The answers should reflect what word(s) should go in the blank an accurate statement. An example is the follow: 'The author of the article is ______.' The question should be a statement.\"\n",
        "  elif selection == \"Short Answer\":\n",
        "    prompt = f\"Please design a {number} question quiz about which reflects the learning objectives (if inputted).  The questions should be short answer. Expect the correct answers to be {length} sentences long.\"\n",
        "  else:\n",
        "    prompt = f\"Please design a {number} question {selection.lower()} quiz based on the context provided and the inputted learning objectives (if applicable).\"\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6IzVTjz5cex"
      },
      "source": [
        "## UI Design\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chatbot V1 (Accordion)"
      ],
      "metadata": {
        "id": "nDsNxoKBu45t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "  gr.Markdown(\"# Oral Exam App\")\n",
        "  gr.Markdown(\"## OpenAI API key\")\n",
        "  with gr.Box():\n",
        "    gr.HTML(\"\"\"Embed your OpenAI API key below; if you haven't created one already, visit\n",
        "      platform.openai.com/account/api-keys\n",
        "    to sign up for an account and get your personal API key\"\"\",\n",
        "            elem_classes=\"textbox_label\")\n",
        "    input = gr.Textbox(show_label=False, type=\"password\", container=False,\n",
        "                      placeholder=\"●●●●●●●●●●●●●●●●●\")\n",
        "    input.change(fn=embed_key, inputs=input, outputs=None)\n",
        "\n",
        "  with gr.Blocks():\n",
        "  #########################\n",
        "  #########Context#########\n",
        "  #########################\n",
        "      with gr.Accordion(\"Context section\"):\n",
        "      ### Should also allow vector stores\n",
        "          gr.Markdown(\"## Please upload the context document(s) for Oral exam\")\n",
        "          context_input = gr.File(label=\"Click to upload context file\",\n",
        "                                  file_count=\"multiple\",\n",
        "                                  file_types=[\".txt\", \".docx\", \".pdf\"])\n",
        "          outputs_context=gr.Textbox(label=\"Context\")\n",
        "          context_input.change(fn=process_file, inputs=context_input, outputs=outputs_context)\n",
        "          # upload_button = gr.Button(value=\"Show context\")\n",
        "          # upload_button.click(process_file, context_input, outputs_context)\n",
        "\n",
        "\n",
        "  #########################\n",
        "  #######Presentation######\n",
        "  #########################\n",
        "\n",
        "      with gr.Accordion(\"Presentation\"):\n",
        "          gr.Markdown(\"## Please record your presentation\")\n",
        "\n",
        "          with gr.Column():\n",
        "            with gr.Row():\n",
        "                file_input = gr.Audio(label=\"Upload Audio\", source=\"upload\", type=\"filepath\")\n",
        "                record_inputs = gr.Audio(label=\"Record Audio\", source=\"microphone\", type=\"filepath\")\n",
        "\n",
        "            gr.Markdown(\"## Transcribe the audio uploaded or recorded\")\n",
        "            outputs_transcribe=gr.Textbox(label=\"Transcription\")\n",
        "\n",
        "            file_input.change(fn=transcribe, inputs=file_input, outputs=outputs_transcribe)\n",
        "            record_inputs.change(fn=transcribe, inputs=record_inputs, outputs=outputs_transcribe)\n",
        "\n",
        "          # with gr.Blocks():\n",
        "          #     gr.Markdown(\"\"\"\n",
        "          #     ## Generate follow-up questions from the presentation\n",
        "          #     \"\"\")\n",
        "          #     with gr.Row():\n",
        "          #       with gr.Column():\n",
        "          #         prompt_button = gr.Button(\"Generate follow-up questions\")\n",
        "          #         presentation_qa = gr.Textbox(label=\"Generated prompt (save or copy)\", show_copy_button=True)\n",
        "          #         prompt_button.click(generate_presentation_questions,\n",
        "          #                         inputs=[outputs_context,outputs_transcribe],\n",
        "          #                         outputs=presentation_qa)\n",
        "\n",
        "  #########################\n",
        "  ######Oral Exam #########\n",
        "  #########################\n",
        "      with gr.Accordion(\"Oral Exam\"):\n",
        "          gr.Markdown(\"\"\"\n",
        "          ## Generate a Premade Prompt\n",
        "          Select your type and number of desired questions. Click \"Generate Prompt\" to get your premade prompt,\n",
        "          and then \"Insert Prompt into Chat\" to copy the text into the chat interface below. \\\n",
        "          You can also copy the prompt using the icon in the upper right corner and paste directly into the input box when interacting with the model.\n",
        "          \"\"\")\n",
        "          with gr.Row():\n",
        "            with gr.Column():\n",
        "              question_type = gr.Dropdown([\"Multiple Choice\", \"True or False\", \"Short Answer\", \"Fill in the Blank\", \"Random\"], label=\"Question Type\")\n",
        "              number_of_questions = gr.Textbox(label=\"Enter desired number of questions\")\n",
        "              sa_desired_length = gr.Dropdown([\"1-2\", \"3-4\", \"5-6\", \"6 or more\"], label = \"For short answer questions only, choose the desired sentence length for answers. The default value is 1-2 sentences.\")\n",
        "            with gr.Column():\n",
        "              prompt_button = gr.Button(\"Generate Prompt\")\n",
        "              premade_prompt_output = gr.Textbox(label=\"Generated prompt (save or copy)\", show_copy_button=True)\n",
        "              prompt_button.click(prompt_select,\n",
        "                              inputs=[question_type, number_of_questions, sa_desired_length],\n",
        "                              outputs=premade_prompt_output)\n",
        "\n",
        " ########################\n",
        "  ##Question Generation###\n",
        "  ########################\n",
        "      with gr.Accordion(\"Question section\"):\n",
        "          gr.Markdown(\"## Questions\")\n",
        "          with gr.Row():\n",
        "            with gr.Column():\n",
        "\n",
        "                outputs_qa=gr.Textbox(label=\"Generate questions or Use your own questions\")\n",
        "                btn1 = gr.Button(value= \"Generate presentation questions\")\n",
        "                btn2 = gr.Button(value=\"Generate oral exam questions\")\n",
        "\n",
        "                btn1.click(generate_presentation_questions,\n",
        "                                    inputs=[outputs_context,outputs_transcribe],\n",
        "                                    outputs=outputs_qa)\n",
        "                btn2.click(generate_questions, inputs=[outputs_context, premade_prompt_output], outputs=outputs_qa)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # with gr.Column():\n",
        "            #   submit_question=gr.Textbox(label=\"Use existing questions\")\n",
        "            #   btn4 = gr.Button(value=\"Use these questions\")\n",
        "              # btn4.click(use_this_question, inputs=outputs_transcribe, outputs=None)\n",
        "\n",
        "\n",
        "  #########################\n",
        "  #######Instruction#######\n",
        "  #########################\n",
        "          instruction_qa_input = gr.File(label=\"Click to upload instruction file\",\n",
        "                                  file_count=\"multiple\",\n",
        "                                  file_types=[\".txt\", \".docx\", \".pdf\"])\n",
        "          instruction_qa=gr.Textbox(label=\"Or please enter the instruction for question/answering section\")\n",
        "          instruction_qa.change(fn=process_file, inputs=context_input, outputs=outputs_context)\n",
        "\n",
        "\n",
        "  #########################\n",
        "  #########Audio QA########\n",
        "  #########################\n",
        "      with gr.Accordion(\"Audio QA section\"):\n",
        "          gr.Markdown(\"## Question answering\")\n",
        "          gr.Markdown(\"### When you are ready to answer questions, press the 'I am ready' button\")\n",
        "          ##### This may be iterative\n",
        "          chatbot = gr.Chatbot([],\n",
        "                                  elem_id=\"chatbot\",\n",
        "                                  height=300)\n",
        "          state = gr.State()\n",
        "          message = gr.Textbox(show_label=False,\n",
        "                              placeholder=\"Your answer will be transcribed here\",\n",
        "                              container=False)\n",
        "          ready_button = gr.Button(value=\"I am ready\")\n",
        "          ready_button.click(message_and_history, inputs=[message, instruction_qa, outputs_qa, state], outputs=[chatbot, state])\n",
        "\n",
        "          hidden = gr.Textbox(visible = False)\n",
        "          btn_record = gr.Audio(label=\"Record Audio\", source=\"microphone\", type=\"filepath\")\n",
        "          btn_record.change(fn=transcribe, inputs=btn_record, outputs=message)\n",
        "          btn_record.clear(use_these_questions, inputs = hidden, outputs = message)\n",
        "\n",
        "          submit = gr.Button(\"Submit\")\n",
        "          submit.click(message_and_history,\n",
        "                      inputs=[message, instruction_qa, outputs_qa, state],\n",
        "                      outputs=[chatbot, state])\n",
        "\n",
        "          message_records = gr.Textbox(show_label=False,\n",
        "                              container=False)\n",
        "          show_records = gr.Button(\"Show QA history\")\n",
        "          show_records.click(use_these_questions,\n",
        "                      inputs=state,\n",
        "                      outputs=message_records)\n",
        "\n",
        "  #########################\n",
        "  #######Evaluation########\n",
        "  #########################\n",
        "      with gr.Accordion(\"Evaluation section\"):\n",
        "          gr.Markdown(\"## Evaluation\")\n",
        "          with gr.Tab(\"General evalution\"):\n",
        "            evalution=gr.Textbox(label=\"AI Evaluation\")\n",
        "            btn5 = gr.Button(value=\"Evaluate\")\n",
        "            btn5.click(ai_evaluate, inputs=[outputs_context, outputs_transcribe, message_records, instruction_qa], outputs=evalution)\n",
        "          with gr.Tab(\"Quantitative evalution\"):\n",
        "            table_output = gr.Dataframe(label = \"Some kind of evaluation metrics?\")\n",
        "            btn6 = gr.Button(value=\"Evaluate\")\n",
        "            # btn6.click(ai_evaluate, inputs=[outputs_context, message_records, outputs_qa], outputs=table_output)\n",
        "\n",
        "  # demo.launch()\n",
        "  # demo.launch(share=True)\n",
        "  demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "uQH0kAYCu9wf",
        "outputId": "8e8e3f37-b659-45a5-baba-9ce25a58ab5a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:833: UserWarning: Expected 3 arguments for function <function generate_presentation_questions at 0x782e51cf6200>, received 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:837: UserWarning: Expected at least 3 arguments for function <function generate_presentation_questions at 0x782e51cf6200>, received 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chatbot VF (Tab)"
      ],
      "metadata": {
        "id": "2dKuYmYYKZ2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
        "  gr.Markdown(\"# Oral Exam App\")\n",
        "  gr.Markdown(\"## OpenAI API key\")\n",
        "  with gr.Box():\n",
        "    gr.HTML(\"\"\"Embed your OpenAI API key below; if you haven't created one already, visit\n",
        "      platform.openai.com/account/api-keys\n",
        "    to sign up for an account and get your personal API key\"\"\",\n",
        "            elem_classes=\"textbox_label\")\n",
        "    input = gr.Textbox(show_label=False, type=\"password\", container=False,\n",
        "                      placeholder=\"●●●●●●●●●●●●●●●●●\")\n",
        "    input.change(fn=embed_key, inputs=input, outputs=None)\n",
        "\n",
        "  with gr.Blocks():\n",
        "  #########################\n",
        "  #########Context#########\n",
        "  #########################\n",
        "      with gr.Accordion(\"Context section\"):\n",
        "      ### Should also allow vector stores\n",
        "          gr.Markdown(\"## Please upload the context document(s) for oral exam or presentation\")\n",
        "          context_input = gr.File(label=\"Click to upload context file\",\n",
        "                                  file_count=\"multiple\",\n",
        "                                  file_types=[\".txt\", \".docx\", \".pdf\"])\n",
        "          outputs_context=gr.Textbox(label=\"Context\")\n",
        "          context_input.change(fn=process_file, inputs=context_input, outputs=outputs_context)\n",
        "          # upload_button = gr.Button(value=\"Show context\")\n",
        "          # upload_button.click(process_file, context_input, outputs_context)\n",
        "\n",
        "\n",
        "  #########################\n",
        "  #######Presentation######\n",
        "  #########################\n",
        "      with gr.Tab(\"Presentation Mode\"):\n",
        "          gr.Markdown(\"## Please record your presentation\")\n",
        "\n",
        "  #######Upload Audio######\n",
        "          with gr.Column():\n",
        "            with gr.Row():\n",
        "                file_input = gr.Audio(label=\"Upload Audio\", source=\"upload\", type=\"filepath\")\n",
        "                record_inputs = gr.Audio(label=\"Record Audio\", source=\"microphone\", type=\"filepath\")\n",
        "\n",
        "            gr.Markdown(\"## Transcribe the audio uploaded or recorded\")\n",
        "            outputs_transcribe=gr.Textbox(label=\"Transcription\")\n",
        "\n",
        "            file_input.change(fn=transcribe, inputs=file_input, outputs=outputs_transcribe)\n",
        "            record_inputs.change(fn=transcribe, inputs=record_inputs, outputs=outputs_transcribe)\n",
        "\n",
        "  #######Instruction######\n",
        "            gr.Markdown(\"## Instructions for QA section\")\n",
        "            instruction_presentation_qa_input = gr.File(label=\"Click to upload instruction file\",\n",
        "                                  file_count=\"multiple\",\n",
        "                                  file_types=[\".txt\", \".docx\", \".pdf\"])\n",
        "            instruction_presentation_qa=gr.Textbox(label=\"Or please enter the instruction/grading criteria for question/answering section\")\n",
        "            instruction_presentation_qa.change(fn=process_file, inputs=instruction_presentation_qa_input, outputs=instruction_presentation_qa)\n",
        "\n",
        "  #######Question Generation######\n",
        "            gr.Markdown(\"## Questions\")\n",
        "            with gr.Row():\n",
        "              with gr.Column():\n",
        "                presentation_qa=gr.Textbox(label=\"Generate questions or Use your own questions\")\n",
        "                btn_presentation = gr.Button(value=\"Generate questions\")\n",
        "                btn_presentation.click(generate_presentation_questions, inputs=[outputs_context, outputs_transcribe, instruction_presentation_qa], outputs=presentation_qa)\n",
        "\n",
        "  #######Chatbot audio QA######\n",
        "            with gr.Accordion(\"Audio Chatbot QA section\"):\n",
        "              gr.Markdown(\"## Question answering\")\n",
        "              gr.Markdown(\"### When you are ready to answer questions, press the 'I am ready' button\")\n",
        "              ##### This may be iterative\n",
        "              chatbot = gr.Chatbot([],\n",
        "                                      elem_id=\"chatbot\",\n",
        "                                      height=300)\n",
        "              state = gr.State()\n",
        "              message = gr.Textbox(show_label=False,\n",
        "                                  placeholder=\"Your answer will be transcribed here\",\n",
        "                                  container=False)\n",
        "              ready_button = gr.Button(value=\"I am ready\")\n",
        "              ready_button.click(message_and_history, inputs=[message, instruction_presentation_qa_input, presentation_qa, state], outputs=[chatbot, state])\n",
        "\n",
        "              hidden = gr.Textbox(visible = False)\n",
        "              btn_record = gr.Audio(label=\"Record Audio\", source=\"microphone\", type=\"filepath\")\n",
        "              btn_record.change(fn=transcribe, inputs=btn_record, outputs=message)\n",
        "              btn_record.clear(use_these_questions, inputs = hidden, outputs = message)\n",
        "\n",
        "              submit = gr.Button(\"Submit\")\n",
        "              submit.click(message_and_history,\n",
        "                          inputs=[message, instruction_presentation_qa_input, presentation_qa, state],\n",
        "                          outputs=[chatbot, state])\n",
        "\n",
        "              gr.Markdown(\"### Once all questions are answered, please click 'DONE' button and QA history will be shown below\")\n",
        "              message_records = gr.Textbox(show_label=False,\n",
        "                                  container=False)\n",
        "              show_records = gr.Button(\"DONE\")\n",
        "              show_records.click(use_these_questions,\n",
        "                          inputs=state,\n",
        "                          outputs=message_records)\n",
        "\n",
        "  #######Evaluation######\n",
        "            gr.Markdown(\"## Evaluation\")\n",
        "            evalution=gr.Textbox(label=\"AI Evaluation\")\n",
        "            btn_evaluation_presentation = gr.Button(value=\"Evaluate\")\n",
        "            btn_evaluation_presentation.click(ai_evaluate, inputs=[outputs_context, outputs_transcribe, message_records, instruction_presentation_qa], outputs=evalution)\n",
        "\n",
        "\n",
        "  #########################\n",
        "  ######Oral Exam #########\n",
        "  #########################\n",
        "      with gr.Tab(\"Oral Exam Mode\"):\n",
        "\n",
        "            gr.Markdown(\"\"\"\n",
        "            ## Generate a Premade Prompt for Question Generation\n",
        "            Select your type and number of desired questions. Click \"Generate Prompt\" to get your premade prompt for question generation.\n",
        "            You can also modify the prompt.\n",
        "            \"\"\")\n",
        "            with gr.Row():\n",
        "              with gr.Column():\n",
        "                question_type_oral = gr.Dropdown([\"Multiple Choice\", \"True or False\", \"Short Answer\", \"Fill in the Blank\", \"Random\"], label=\"Question Type\")\n",
        "                number_of_questions_oral = gr.Textbox(label=\"Enter desired number of questions\")\n",
        "                sa_desired_length_oral = gr.Dropdown([\"1-2\", \"3-4\", \"5-6\", \"6 or more\"], label = \"For short answer questions only, choose the desired sentence length for answers. The default value is 1-2 sentences.\")\n",
        "              with gr.Column():\n",
        "                prompt_button = gr.Button(\"Generate Prompt\")\n",
        "                premade_prompt_output = gr.Textbox(label=\"Generated prompt\", show_copy_button=True)\n",
        "                prompt_button.click(prompt_select,\n",
        "                                inputs=[question_type_oral, number_of_questions_oral, sa_desired_length_oral],\n",
        "                                outputs=premade_prompt_output)\n",
        "\n",
        " #######Instruction######\n",
        "            gr.Markdown(\"## Instructions for QA section\")\n",
        "            instruction_oral_exam_qa_input = gr.File(label=\"Click to upload instruction file\",\n",
        "                                  file_count=\"multiple\",\n",
        "                                  file_types=[\".txt\", \".docx\", \".pdf\"])\n",
        "            instruction_oral_exam_qa=gr.Textbox(label=\"Or please enter the instruction/grading criteria for question/answering section\")\n",
        "            instruction_oral_exam_qa.change(fn=process_file, inputs=instruction_oral_exam_qa_input, outputs=instruction_oral_exam_qa)\n",
        "\n",
        "  #######Question Generation######\n",
        "            gr.Markdown(\"## Questions\")\n",
        "            with gr.Row():\n",
        "              with gr.Column():\n",
        "                oral_exam_qa=gr.Textbox(label=\"Generate questions or Use your own questions\")\n",
        "                btn_oral_exam = gr.Button(value=\"Generate questions\")\n",
        "                btn_oral_exam.click(generate_oral_exam_questions, inputs=[outputs_context, premade_prompt_output], outputs=oral_exam_qa)\n",
        "\n",
        "  #######Chatbot audio QA######\n",
        "            with gr.Accordion(\"Audio Chatbot QA section\"):\n",
        "              gr.Markdown(\"## Question answering\")\n",
        "              gr.Markdown(\"### When you are ready to answer questions, press the 'I am ready' button\")\n",
        "              ##### This may be iterative\n",
        "              chatbot_oral = gr.Chatbot([],\n",
        "                                      elem_id=\"chatbot\",\n",
        "                                      height=300)\n",
        "              state_oral = gr.State()\n",
        "              message_oral = gr.Textbox(show_label=False,\n",
        "                                  placeholder=\"Your answer will be transcribed here\",\n",
        "                                  container=False)\n",
        "              ready_button_oral = gr.Button(value=\"I am ready\")\n",
        "              ready_button_oral.click(message_and_history, inputs=[message_oral, instruction_oral_exam_qa, oral_exam_qa, state_oral], outputs=[chatbot_oral, state_oral])\n",
        "\n",
        "              hidden_oral = gr.Textbox(visible = False)\n",
        "              btn_record_oral = gr.Audio(label=\"Record Audio\", source=\"microphone\", type=\"filepath\")\n",
        "              btn_record_oral.change(fn=transcribe, inputs=btn_record_oral, outputs=message_oral)\n",
        "              btn_record_oral.clear(use_these_questions, inputs = hidden_oral, outputs = message_oral)\n",
        "\n",
        "              submit_oral = gr.Button(\"Submit\")\n",
        "              submit_oral.click(message_and_history,\n",
        "                          inputs=[message_oral, instruction_oral_exam_qa, oral_exam_qa, state_oral],\n",
        "                          outputs=[chatbot_oral, state_oral])\n",
        "\n",
        "              gr.Markdown(\"### Once all questions are answered, please click 'DONE' button and QA history will be shown below\")\n",
        "              message_records_oral = gr.Textbox(show_label=False,\n",
        "                                  container=False)\n",
        "              show_records_oral = gr.Button(\"DONE\")\n",
        "              show_records_oral.click(use_these_questions,\n",
        "                          inputs=state_oral,\n",
        "                          outputs=message_records_oral)\n",
        "\n",
        "  #######Evaluation######\n",
        "            gr.Markdown(\"## Evaluation\")\n",
        "            evalution_oral=gr.Textbox(label=\"AI Evaluation\")\n",
        "            btn_evaluation_oral = gr.Button(value=\"Evaluate\")\n",
        "            btn_evaluation_oral.click(ai_evaluate_oral_exam, inputs=[outputs_context, message_records_oral, instruction_oral_exam_qa], outputs=evalution_oral)\n",
        "\n",
        "\n",
        "  demo.launch()\n",
        "  # demo.launch(share=True)\n",
        "  # demo.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "IiyJZrcUKX8T",
        "outputId": "b7df3f7b-3372-463b-8e0e-2588f3b7a983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2EVIogW69Fd"
      },
      "source": [
        "## What's left\n",
        "- vector store (link) upload\n",
        "- how to not show the warning when transcribing\n",
        "- better prompt for evaluation\n",
        "- try ChatInterface of Gradio\n",
        "- Theming for Gradio: https://www.gradio.app/guides/theming-guide\n",
        "- Add more instructions\n",
        "- Determine where to put the 'instruction' section. This could be different for presentation mode and oral exam mode"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}